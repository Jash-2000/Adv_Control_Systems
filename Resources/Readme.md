# TO/MPC
Model Predictive Control (MPC), also called Receding Horizon Control, and a Preview Control approach that implements in MPC via finding an analytically-solvable offline solution. 
See [Kajita03](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Kajita03.pdf), on the Preview Control approach for a very simplified humanoid planning approach, which in turn depends on familiarity with: [katayama85](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/katayama85.pdf). 
Here’s a broader overview of MPC methods related to legged locomotion: [MPC](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Model%20predictive%20control%20of%20legged%20and%20humanoid%20robots%20%20models%20and%20algorithms.pdf)

Trajectory Optimization. Here, we seek what might be considered an “open-loop” set of states, x(k), and control inputs, u(k), that obey required dynamics (as constraints) and are also (locally) optimal, with 
respect to some cost funtion.
Some Interesting Tutorial to learn more on this are: [Youtube_Link](https://www.youtube.com/watch?v=wlkRYMVUZTs) and [Matthew_Kelly](https://www.matthewpeterkelly.com/tutorials/index.html).

# Kalman Filter Lp at steady state
A key insight is that when you run a Kalman filter, although the actual state estimates depend on initial conditions and sensor inputs and process noise that is encountered, the evolution of the KALMAN GAIN only depends on Ad, Bd, Q, R, and P0 -- which means you can pre-compute a steady-state Lp matrix.The example code below does this for dynamics linearized near the "pendubot fully down" equilibrium - [Pendubot_Kalman_Estimation](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Kalman_steady_state_Lp.m)

# PFL/LQR
A 1995 paper by Prof. Mark Spong, on using partial feedback linearization (PFL) for swing-up of the system, and then stabilizing near the fully-upright equilibrium via an LQR (linear quadratic regulator) balancing control - [Spong95](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Spong95.pdf) and some additional materials to supplement the topics: [UCSB_Lect_2](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Lec2_ece238_Supplement.pdf), [UCSB_Lect_3](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Lec3_ece238_Supplement.pdf), [UCSB_Lect_3B](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Lec3_ece238_SimplePendulum.pdf).
 
Also look at the Lagrangian method for deriving equations of motion: [Lecture9_Lagrangian_EOM.pdf](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Lecture9_Lagrangian_EOM.pdf), [Lecture10_Lagrangian_EOM_pt2.pdf](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Lecture10_Lagrangian_EOM_pt2.pdf),[Lecture11_segway_eom.pdf](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Lecture11_segway_eom.pdf),[KinEnergy_vs_coenergy.pdf](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/KinEnergy_vs_coenergy.pdf), [fulldiff.m](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/fulldiff.m), [segway_eom.m](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/segway_eom.m), [Cheat_eom.pdf](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/Cheat_eom.pdf).
For Resources on the One-Link Pendulum system: [SimplePendulum_eom.m](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/SimplePendulum_eom.m), [fulldiff.m](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/fulldiff.m), [dx_fn.m](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/dx_fn.m), [set_params.m](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/set_params.m), [test_dx_fn.m](https://github.com/Jash-2000/Adv_Control_Systems/blob/main/Resources/test_dx_fn.m).
